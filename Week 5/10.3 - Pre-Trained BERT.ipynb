{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","authorship_tag":"ABX9TyNJqC9OtFqdFvRSn3wlTaXQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#**Pre-Trained BERT Model**\n","\n","\n","\n","\n"],"metadata":{"id":"iqBsw2Dyo1BA"}},{"cell_type":"markdown","source":["We can download this model from Keras Hub. We will work with a subsequently released version of BERT, RoBERTA, which is robustly optimized (Ro). The model's main value was that it was trained on 10x the amount of data though, so it's better tuned."],"metadata":{"id":"OAdMvgp2cxkL"}},{"cell_type":"code","source":["import keras_hub\n","\n","# Backbone here refers to the RoBERTa base layers\n","tokenizer = keras_hub.models.Tokenizer.from_preset(\"roberta_base_en\")\n","backbone = keras_hub.models.Backbone.from_preset(\"roberta_base_en\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"70L05q-H_y9w","executionInfo":{"status":"ok","timestamp":1744830482454,"user_tz":240,"elapsed":68947,"user":{"displayName":"Gordon Burtch","userId":"10144756805379529333"}},"outputId":"03849539-2dca-42c9-f71a-8547607c97fa"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading from https://www.kaggle.com/api/v1/models/keras/roberta/keras/roberta_base_en/2/download/config.json...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 498/498 [00:00<00:00, 764kB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Downloading from https://www.kaggle.com/api/v1/models/keras/roberta/keras/roberta_base_en/2/download/tokenizer.json...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 463/463 [00:00<00:00, 686kB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Downloading from https://www.kaggle.com/api/v1/models/keras/roberta/keras/roberta_base_en/2/download/assets/tokenizer/vocabulary.json...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 0.99M/0.99M [00:01<00:00, 755kB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Downloading from https://www.kaggle.com/api/v1/models/keras/roberta/keras/roberta_base_en/2/download/assets/tokenizer/merges.txt...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 446k/446k [00:01<00:00, 428kB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Downloading from https://www.kaggle.com/api/v1/models/keras/roberta/keras/roberta_base_en/2/download/model.weights.h5...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 474M/474M [00:31<00:00, 15.9MB/s]\n"]}]},{"cell_type":"markdown","source":["We need to use the tokenizer that goes with the model to make sure it pre-processes our text in a way that the model expects."],"metadata":{"id":"_NSPv4qcAUP-"}},{"cell_type":"code","source":["tokenizer(\"The quick brown fox\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vJYJzpaKAR5D","executionInfo":{"status":"ok","timestamp":1744830543768,"user_tz":240,"elapsed":1823,"user":{"displayName":"Gordon Burtch","userId":"10144756805379529333"}},"outputId":"d6189434-247d-4d89-f43a-0d9f71ce867c"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(4,), dtype=int32, numpy=array([  133,  2119,  6219, 23602], dtype=int32)>"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["Here are the base layers we loaded. Notice that it is essentially a token embedding layer with some normalization afterward, some dropout to the embeddings to avoid overfitting, and then a ton of stacked transformer encoders."],"metadata":{"id":"B0papAoZAfiK"}},{"cell_type":"code","source":["backbone.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":951},"id":"Vutdk_gfAgdR","executionInfo":{"status":"ok","timestamp":1744830608939,"user_tz":240,"elapsed":126,"user":{"displayName":"Gordon Burtch","userId":"10144756805379529333"}},"outputId":"b8d8ca7f-f80c-4a76-858a-8d6dbf993397"},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"roberta_backbone\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"roberta_backbone\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ token_ids           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ embeddings          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │ \u001b[38;5;34m38,996,736\u001b[0m │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n","│ (\u001b[38;5;33mTokenAndPositionE…\u001b[0m │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ embeddings_layer_n… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │      \u001b[38;5;34m1,536\u001b[0m │ embeddings[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n","│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ embeddings_dropout  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ embeddings_layer… │\n","│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ padding_mask        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ transformer_layer_0 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,087,872\u001b[0m │ embeddings_dropo… │\n","│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ transformer_layer_1 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,087,872\u001b[0m │ transformer_laye… │\n","│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ transformer_layer_2 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,087,872\u001b[0m │ transformer_laye… │\n","│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ transformer_layer_3 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,087,872\u001b[0m │ transformer_laye… │\n","│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ transformer_layer_4 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,087,872\u001b[0m │ transformer_laye… │\n","│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ transformer_layer_5 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,087,872\u001b[0m │ transformer_laye… │\n","│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ transformer_layer_6 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,087,872\u001b[0m │ transformer_laye… │\n","│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ transformer_layer_7 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,087,872\u001b[0m │ transformer_laye… │\n","│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ transformer_layer_8 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,087,872\u001b[0m │ transformer_laye… │\n","│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ transformer_layer_9 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,087,872\u001b[0m │ transformer_laye… │\n","│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ transformer_layer_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,087,872\u001b[0m │ transformer_laye… │\n","│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ transformer_layer_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,087,872\u001b[0m │ transformer_laye… │\n","│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ token_ids           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ embeddings          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │ <span style=\"color: #00af00; text-decoration-color: #00af00\">38,996,736</span> │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionE…</span> │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ embeddings_layer_n… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │ embeddings[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ embeddings_dropout  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embeddings_layer… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ padding_mask        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ transformer_layer_0 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,087,872</span> │ embeddings_dropo… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ transformer_layer_1 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,087,872</span> │ transformer_laye… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ transformer_layer_2 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,087,872</span> │ transformer_laye… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ transformer_layer_3 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,087,872</span> │ transformer_laye… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ transformer_layer_4 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,087,872</span> │ transformer_laye… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ transformer_layer_5 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,087,872</span> │ transformer_laye… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ transformer_layer_6 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,087,872</span> │ transformer_laye… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ transformer_layer_7 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,087,872</span> │ transformer_laye… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ transformer_layer_8 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,087,872</span> │ transformer_laye… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ transformer_layer_9 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,087,872</span> │ transformer_laye… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ transformer_layer_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,087,872</span> │ transformer_laye… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ transformer_layer_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,087,872</span> │ transformer_laye… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m124,052,736\u001b[0m (473.22 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">124,052,736</span> (473.22 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m124,052,736\u001b[0m (473.22 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">124,052,736</span> (473.22 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","source":["Let's try using this pre-trained model with our IMDB reviews..."],"metadata":{"id":"h1z49D-xA0Wl"}},{"cell_type":"code","source":["import os, pathlib, shutil, random, keras\n","\n","zip_path = keras.utils.get_file(\n","    origin=\"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",\n","    fname=\"imdb\",\n","    extract=True,\n",")\n","\n","imdb_extract_dir = pathlib.Path(zip_path) / \"aclImdb\"\n","train_dir = pathlib.Path(\"imdb_train\")\n","test_dir = pathlib.Path(\"imdb_test\")\n","val_dir = pathlib.Path(\"imdb_val\")\n","\n","shutil.copytree(imdb_extract_dir / \"test\", test_dir, dirs_exist_ok=True)\n","\n","val_percentage = 0.2\n","for category in (\"neg\", \"pos\"):\n","    src_dir = imdb_extract_dir / \"train\" / category\n","    src_files = os.listdir(src_dir)\n","    random.Random(1337).shuffle(src_files)\n","    num_val_samples = int(len(src_files) * val_percentage)\n","\n","    os.makedirs(train_dir / category, exist_ok=True)\n","    os.makedirs(val_dir / category, exist_ok=True)\n","    for index, file in enumerate(src_files):\n","        if index < num_val_samples:\n","            shutil.copy(src_dir / file, val_dir / category / file)\n","        else:\n","            shutil.copy(src_dir / file, train_dir / category / file)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lp77dWAFA2y7","executionInfo":{"status":"ok","timestamp":1744830733767,"user_tz":240,"elapsed":37445,"user":{"displayName":"Gordon Burtch","userId":"10144756805379529333"}},"outputId":"c242baf2-6ef8-4d41-da8d-1251eabcae54"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","\u001b[1m84125825/84125825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 0us/step\n"]}]},{"cell_type":"markdown","source":["Create our Tensorflow Dataset objects from the .txt files now"],"metadata":{"id":"DUcOJnPQA88x"}},{"cell_type":"code","source":["batch_size = 16\n","train_ds = keras.utils.text_dataset_from_directory(\n","    train_dir, batch_size=batch_size\n",")\n","val_ds = keras.utils.text_dataset_from_directory(\n","    val_dir, batch_size=batch_size\n",")\n","test_ds = keras.utils.text_dataset_from_directory(\n","    test_dir, batch_size=batch_size\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AFLy4MybA8TM","executionInfo":{"status":"ok","timestamp":1744830780576,"user_tz":240,"elapsed":3037,"user":{"displayName":"Gordon Burtch","userId":"10144756805379529333"}},"outputId":"3b108db9-39d0-46f4-92f8-0576514f0110"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 20000 files belonging to 2 classes.\n","Found 5000 files belonging to 2 classes.\n","Found 25000 files belonging to 2 classes.\n"]}]},{"cell_type":"markdown","source":["We apply the RoBERTa tokenizer to our datasets now. Before we go to the RoBERTa tokenizer, however, we need to add some start and end tokens, and some padding tokens, that were present in the dataset that was used for training RoBERTa."],"metadata":{"id":"Qy87mXyzBGpR"}},{"cell_type":"code","source":["# We are 'packing' on some additional tokens here. Sequences up to 512 tokens, adding the start token to our reviews, the end token, and the padding token for reviews shorter than 512 words.\n","def preprocess(text, label):\n","    packer = keras_hub.layers.StartEndPacker(\n","        sequence_length=512,\n","        start_value=tokenizer.start_token_id,\n","        end_value=tokenizer.end_token_id,\n","        pad_value=tokenizer.pad_token_id,\n","        return_padding_mask=True,\n","    )\n","\n","    # After adding those tokens, we can apply RoBERTa's tokenizer\n","    token_ids, padding_mask = packer(tokenizer(text))\n","    return {\"token_ids\": token_ids, \"padding_mask\": padding_mask}, label\n","\n","# And now that our preprocessing function is written, we can apply it to our Tensorflow Datasets\n","preprocessed_train_ds = train_ds.map(preprocess)\n","preprocessed_val_ds = val_ds.map(preprocess)\n","preprocessed_test_ds = test_ds.map(preprocess)"],"metadata":{"id":"lQKUx605BJ-W","executionInfo":{"status":"ok","timestamp":1744830901925,"user_tz":240,"elapsed":9449,"user":{"displayName":"Gordon Burtch","userId":"10144756805379529333"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["Here is a pre-processed batch of data. We have integer sequences per review, and a masking vector for each one that tells RoBERTa which tokens it can ignore at inference."],"metadata":{"id":"emLFbcRYBqkB"}},{"cell_type":"code","source":["next(iter(preprocessed_train_ds))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"037zIY82BsIl","executionInfo":{"status":"ok","timestamp":1744830917539,"user_tz":240,"elapsed":2096,"user":{"displayName":"Gordon Burtch","userId":"10144756805379529333"}},"outputId":"5d85c302-cd9d-49c8-f884-f29cac5c5029"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["({'token_ids': <tf.Tensor: shape=(16, 512), dtype=int32, numpy=\n","  array([[    0,   713,  1569, ...,     1,     1,     1],\n","         [    0,   100,    78, ...,   693,   109,     2],\n","         [    0,   713,    16, ...,     1,     1,     1],\n","         ...,\n","         [    0,  7682,   200, ...,    12, 23760,     2],\n","         [    0,   100, 31124, ...,     1,     1,     1],\n","         [    0,   100,   524, ...,     1,     1,     1]], dtype=int32)>,\n","  'padding_mask': <tf.Tensor: shape=(16, 512), dtype=bool, numpy=\n","  array([[ True,  True,  True, ..., False, False, False],\n","         [ True,  True,  True, ...,  True,  True,  True],\n","         [ True,  True,  True, ..., False, False, False],\n","         ...,\n","         [ True,  True,  True, ...,  True,  True,  True],\n","         [ True,  True,  True, ..., False, False, False],\n","         [ True,  True,  True, ..., False, False, False]])>},\n"," <tf.Tensor: shape=(16,), dtype=int32, numpy=array([0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0], dtype=int32)>)"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["Okay, now we can add some Dense layers onto the RoBERTa backbone and use it for our predictions!"],"metadata":{"id":"_MHAbDQ9CBiI"}},{"cell_type":"code","source":["from keras import layers\n","\n","inputs = backbone.input\n","x = backbone(inputs)\n","\n","# Freeze the backbone layers\n","backbone.trainable = False\n","\n","# This is isolating a specific embedding from RoBERTa's backbone output that is akin to the document embedding.\n","# This embedding is associated with the CLS (classification) token.\n","# The CLS token is a specific token (a fixed value) that is added at the beginning of every textual sequence in RoBERTa's training data.\n","# The Neural Net learns to shift this token's embedding around depending on all the words that appear in a given sentence, to improve masked word prediction.\n","# As the model achieves its self-supervised prediction goal, it learns how to produce a CLS token embedding for a given sequence of text that captures relevant information about the entire sentence.\n","# Note that this is generally more useful / less noisy than doing something noisy like averaging all the word embeddings from the sentence.\n","x = x[:, 0, :]\n","\n","x = layers.Dropout(0.1)(x)\n","\n","# Each embedding is a 768 dimensional vectors; we are just relu activating the embedding, then doing dropout and going to a sigmoid prediction.\n","x = layers.Dense(768, activation=\"relu\")(x)\n","x = layers.Dropout(0.1)(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","\n","classifier = keras.Model(inputs, outputs)\n","\n","classifier.compile(\n","    optimizer=keras.optimizers.Adam(5e-5),\n","    loss=\"binary_crossentropy\",\n","    metrics=[\"accuracy\"],\n",")\n","\n","classifier.fit(\n","    preprocessed_train_ds,\n","    validation_data=preprocessed_val_ds,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QS-JVSnfCGBJ","executionInfo":{"status":"ok","timestamp":1744832014158,"user_tz":240,"elapsed":117519,"user":{"displayName":"Gordon Burtch","userId":"10144756805379529333"}},"outputId":"c8134db6-55c8-4d60-edaa-67e277d85dcb"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 67ms/step - accuracy: 0.9394 - loss: 0.1709 - val_accuracy: 0.9242 - val_loss: 0.1998\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x795e6dfe6e50>"]},"metadata":{},"execution_count":16}]}]}